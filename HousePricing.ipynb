{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HousePricing.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMV7fPOU9rqB9OI29To0JGt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GumballWatterson00/HousePricingUsingBlendedRegressors/blob/master/HousePricing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkM-bZJ5Rqn0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from google.colab import files\n",
        "import matplotlib.pyplot as plt\n",
        "import io\n",
        "import seaborn as sns\n",
        "from pydrive.auth import GoogleAuth \n",
        "from pydrive.drive import GoogleDrive \n",
        "from google.colab import auth \n",
        "from oauth2client.client import GoogleCredentials \n",
        "\n",
        "auth.authenticate_user() \n",
        "gauth = GoogleAuth() \n",
        "gauth.credentials = GoogleCredentials.get_application_default() \n",
        "ials = GoogleCredentials.get_application_default() \n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwicI6TvXMyF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "link = 'https://drive.google.com/file/d/1TMplQY_UF3f0rZ0UMMUBFiBXu_jC6Y6M/view?usp=sharing'\n",
        "id = link.split(\"/\")[-2] \n",
        "downloaded = drive.CreateFile({'id':id})  \n",
        "downloaded.GetContentFile('Nhà.csv')    \n",
        "df = pd.read_csv('Nhà.csv') \n",
        "df = df.drop(['Giấy tờ pháp lý', 'Số tầng', 'Dài', 'Rộng'], axis=1)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_dJNQvrcw3n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df.dropna()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YblOMBJbc4J_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df.drop(df.columns[0], axis='columns')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIO_R0w6dO2U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " def processing(columns, N, M): \n",
        "  result = []\n",
        "  for i in columns:\n",
        "    i = i.partition(' ')[0].replace(',', '.')\n",
        "    if i.count('.') > 1:\n",
        "      i = float('nan')\n",
        "      result.append(i)\n",
        "    else:\n",
        "      if float(i) <= N or float(i) >= M:\n",
        "        i = float('nan')\n",
        "        result.append(i)\n",
        "      else:\n",
        "        result.append(float(i))\n",
        "  return result"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0jzApmDhVOW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['Giá/m2'] = processing(df['Giá/m2'].to_list(), 30, 200)\n",
        "df['Diện tích'] = processing(df['Diện tích'].to_list(), 20, 100)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGP_Mu5UmroC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df.dropna()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYBJoeZGnjdT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "30c5cded-11d9-49d5-918b-e3be5cb09e18"
      },
      "source": [
        "df"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Ngày</th>\n",
              "      <th>Địa chỉ</th>\n",
              "      <th>Quận</th>\n",
              "      <th>Huyện</th>\n",
              "      <th>Loại hình nhà ở</th>\n",
              "      <th>Số phòng ngủ</th>\n",
              "      <th>Diện tích</th>\n",
              "      <th>Giá/m2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020-08-05</td>\n",
              "      <td>Đường Hoàng Quốc Việt, Phường Nghĩa Đô, Quận C...</td>\n",
              "      <td>Quận Cầu Giấy</td>\n",
              "      <td>Phường Nghĩa Đô</td>\n",
              "      <td>Nhà ngõ, hẻm</td>\n",
              "      <td>5 phòng</td>\n",
              "      <td>46.0</td>\n",
              "      <td>86.96</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2020-08-05</td>\n",
              "      <td>Đường Kim Giang, Phường Kim Giang, Quận Thanh ...</td>\n",
              "      <td>Quận Thanh Xuân</td>\n",
              "      <td>Phường Kim Giang</td>\n",
              "      <td>Nhà mặt phố, mặt tiền</td>\n",
              "      <td>3 phòng</td>\n",
              "      <td>37.0</td>\n",
              "      <td>116.22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2020-08-05</td>\n",
              "      <td>phố minh khai, Phường Minh Khai, Quận Hai Bà T...</td>\n",
              "      <td>Quận Hai Bà Trưng</td>\n",
              "      <td>Phường Minh Khai</td>\n",
              "      <td>Nhà ngõ, hẻm</td>\n",
              "      <td>4 phòng</td>\n",
              "      <td>40.0</td>\n",
              "      <td>65.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2020-08-05</td>\n",
              "      <td>Đường Võng Thị, Phường Thụy Khuê, Quận Tây Hồ,...</td>\n",
              "      <td>Quận Tây Hồ</td>\n",
              "      <td>Phường Thụy Khuê</td>\n",
              "      <td>Nhà ngõ, hẻm</td>\n",
              "      <td>6 phòng</td>\n",
              "      <td>51.0</td>\n",
              "      <td>100.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2020-08-05</td>\n",
              "      <td>Đường Kim Giang, Phường Kim Giang, Quận Thanh ...</td>\n",
              "      <td>Quận Thanh Xuân</td>\n",
              "      <td>Phường Kim Giang</td>\n",
              "      <td>Nhà ngõ, hẻm</td>\n",
              "      <td>4 phòng</td>\n",
              "      <td>36.0</td>\n",
              "      <td>86.11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82489</th>\n",
              "      <td>2019-09-19</td>\n",
              "      <td>Đường Xuân Thủy, Phường Dịch Vọng Hậu, Quận Cầ...</td>\n",
              "      <td>Quận Cầu Giấy</td>\n",
              "      <td>Phường Dịch Vọng Hậu</td>\n",
              "      <td>Nhà ngõ, hẻm</td>\n",
              "      <td>3 phòng</td>\n",
              "      <td>40.0</td>\n",
              "      <td>77.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82490</th>\n",
              "      <td>2019-08-26</td>\n",
              "      <td>Đường Lê Đức Thọ, Phường Mỹ Đình 1, Quận Nam T...</td>\n",
              "      <td>Quận Nam Từ Liêm</td>\n",
              "      <td>Phường Mỹ Đình 1</td>\n",
              "      <td>Nhà phố liền kề</td>\n",
              "      <td>3 phòng</td>\n",
              "      <td>38.0</td>\n",
              "      <td>76.32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82491</th>\n",
              "      <td>2019-08-23</td>\n",
              "      <td>Đường Hồ Tùng Mậu, Phường Phúc Diễn, Quận Bắc ...</td>\n",
              "      <td>Quận Bắc Từ Liêm</td>\n",
              "      <td>Phường Phúc Diễn</td>\n",
              "      <td>Nhà phố liền kề</td>\n",
              "      <td>3 phòng</td>\n",
              "      <td>38.0</td>\n",
              "      <td>81.58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82494</th>\n",
              "      <td>2019-08-05</td>\n",
              "      <td>Đường Quan Hoa, Phường Quan Hoa, Quận Cầu Giấy...</td>\n",
              "      <td>Quận Cầu Giấy</td>\n",
              "      <td>Phường Quan Hoa</td>\n",
              "      <td>Nhà ngõ, hẻm</td>\n",
              "      <td>4 phòng</td>\n",
              "      <td>60.0</td>\n",
              "      <td>101.67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82495</th>\n",
              "      <td>2019-08-05</td>\n",
              "      <td>Đường Hồ Tùng Mậu, Phường Mai Dịch, Quận Cầu G...</td>\n",
              "      <td>Quận Cầu Giấy</td>\n",
              "      <td>Phường Mai Dịch</td>\n",
              "      <td>Nhà phố liền kề</td>\n",
              "      <td>4 phòng</td>\n",
              "      <td>45.0</td>\n",
              "      <td>102.22</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>73600 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             Ngày  ...  Giá/m2\n",
              "0      2020-08-05  ...   86.96\n",
              "1      2020-08-05  ...  116.22\n",
              "2      2020-08-05  ...   65.00\n",
              "3      2020-08-05  ...  100.00\n",
              "4      2020-08-05  ...   86.11\n",
              "...           ...  ...     ...\n",
              "82489  2019-09-19  ...   77.50\n",
              "82490  2019-08-26  ...   76.32\n",
              "82491  2019-08-23  ...   81.58\n",
              "82494  2019-08-05  ...  101.67\n",
              "82495  2019-08-05  ...  102.22\n",
              "\n",
              "[73600 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCUm5PCv0OUi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "880c0c89-4e64-452b-ded6-3c6793153fa9"
      },
      "source": [
        "df.Timestamp = df['Ngày']\n",
        "df.Timestamp = df.Timestamp.astype('datetime64')\n",
        "ADDITIONAL = 1\n",
        "df['Timestamp'] = ((df.Timestamp.dt.year * (10000 * ADDITIONAL)) + (df.Timestamp.dt.month * (100 * ADDITIONAL)) + ((df.Timestamp.dt.day) * ADDITIONAL))\n",
        "df = df.drop('Ngày', axis=1)\n",
        "\n",
        "def processing_bedrooms(columns, N): \n",
        "  result = []\n",
        "  for i in columns:\n",
        "    i = i.partition(' ')[0].replace(',', '.')\n",
        "    if i in ['Nhiều', 'nhiều']:\n",
        "      result.append(11) \n",
        "    elif i.count('.') > 1:\n",
        "      i = float('nan')\n",
        "      result.append(i)\n",
        "    else:\n",
        "      if float(i) < N:\n",
        "        i = float('nan')\n",
        "        result.append(i)\n",
        "      else:\n",
        "        result.append(float(i))\n",
        "  return result\n",
        "\n",
        "df['Số phòng ngủ'] = processing_bedrooms(df['Số phòng ngủ'].to_list(), 1)\n",
        "\n",
        "def encode_and_bind(original_dataframe, feature_to_encode):\n",
        "    dummies = pd.get_dummies(original_dataframe[[feature_to_encode]])\n",
        "    res = pd.concat([original_dataframe, dummies], axis=1)\n",
        "    res = res.drop([feature_to_encode], axis=1)\n",
        "    return(res)\n",
        "\n",
        "or_res = df.drop('Địa chỉ', axis=1)\n",
        "features_to_encode = ['Quận', 'Huyện', 'Loại hình nhà ở']\n",
        "for feature in features_to_encode: \n",
        "  or_res = encode_and_bind(or_res, feature)\n",
        "\n",
        "for feature in or_res.columns:\n",
        "  if any(or_res[feature]) == False:\n",
        "    or_res.drop(feature, axis=1, inplace=True)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljNHGax6ioxv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "res = or_res.copy()"
      ],
      "execution_count": 214,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JT4CeRteyBEi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "res.drop('Timestamp', axis=1, inplace=True)\n",
        "res['Giá'] = res['Giá/m2'] * res['Diện tích'] * 1e6\n",
        "res['Số phòng ngủ'] = np.log1p(res['Số phòng ngủ'])\n",
        "res['Giá'] = np.log1p(res['Giá'])\n",
        "res.drop('Giá/m2', axis=1, inplace=True)\n",
        "res['Diện tích'] = np.log1p(res['Diện tích'])"
      ],
      "execution_count": 215,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YI0e-pS2UDwb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "outputId": "19aaf2aa-4123-4110-8bb4-33a8a47db495"
      },
      "source": [
        "res.describe()"
      ],
      "execution_count": 216,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Số phòng ngủ</th>\n",
              "      <th>Diện tích</th>\n",
              "      <th>Quận_Huyện Chương Mỹ</th>\n",
              "      <th>Quận_Huyện Gia Lâm</th>\n",
              "      <th>Quận_Huyện Hoài Đức</th>\n",
              "      <th>Quận_Huyện Mê Linh</th>\n",
              "      <th>Quận_Huyện Phúc Thọ</th>\n",
              "      <th>Quận_Huyện Sóc Sơn</th>\n",
              "      <th>Quận_Huyện Thanh Oai</th>\n",
              "      <th>Quận_Huyện Thanh Trì</th>\n",
              "      <th>Quận_Huyện Thường Tín</th>\n",
              "      <th>Quận_Huyện Thạch Thất</th>\n",
              "      <th>Quận_Huyện Đan Phượng</th>\n",
              "      <th>Quận_Huyện Đông Anh</th>\n",
              "      <th>Quận_Quận Ba Đình</th>\n",
              "      <th>Quận_Quận Bắc Từ Liêm</th>\n",
              "      <th>Quận_Quận Cầu Giấy</th>\n",
              "      <th>Quận_Quận Hai Bà Trưng</th>\n",
              "      <th>Quận_Quận Hoàn Kiếm</th>\n",
              "      <th>Quận_Quận Hoàng Mai</th>\n",
              "      <th>Quận_Quận Hà Đông</th>\n",
              "      <th>Quận_Quận Long Biên</th>\n",
              "      <th>Quận_Quận Nam Từ Liêm</th>\n",
              "      <th>Quận_Quận Thanh Xuân</th>\n",
              "      <th>Quận_Quận Tây Hồ</th>\n",
              "      <th>Quận_Quận Đống Đa</th>\n",
              "      <th>Quận_Thị xã Sơn Tây</th>\n",
              "      <th>Huyện_Phường Biên Giang</th>\n",
              "      <th>Huyện_Phường Bách Khoa</th>\n",
              "      <th>Huyện_Phường Bùi Thị Xuân</th>\n",
              "      <th>Huyện_Phường Bưởi</th>\n",
              "      <th>Huyện_Phường Bạch Mai</th>\n",
              "      <th>Huyện_Phường Bạch Đằng</th>\n",
              "      <th>Huyện_Phường Bồ Đề</th>\n",
              "      <th>Huyện_Phường Chương Dương</th>\n",
              "      <th>Huyện_Phường Cát Linh</th>\n",
              "      <th>Huyện_Phường Cầu Diễn</th>\n",
              "      <th>Huyện_Phường Cầu Dền</th>\n",
              "      <th>Huyện_Phường Cống Vị</th>\n",
              "      <th>Huyện_Phường Cổ Nhuế 1</th>\n",
              "      <th>...</th>\n",
              "      <th>Huyện_Xã Nguyên Khê</th>\n",
              "      <th>Huyện_Xã Ngũ Hiệp</th>\n",
              "      <th>Huyện_Xã Ngọc Hồi</th>\n",
              "      <th>Huyện_Xã Ngọc Tảo</th>\n",
              "      <th>Huyện_Xã Phù Lỗ</th>\n",
              "      <th>Huyện_Xã Phương Trung</th>\n",
              "      <th>Huyện_Xã Sơn Đồng</th>\n",
              "      <th>Huyện_Xã Tam Hiệp</th>\n",
              "      <th>Huyện_Xã Thanh Liệt</th>\n",
              "      <th>Huyện_Xã Thanh Xuân</th>\n",
              "      <th>Huyện_Xã Tiền Phong</th>\n",
              "      <th>Huyện_Xã Tân Hội</th>\n",
              "      <th>Huyện_Xã Tân Lập</th>\n",
              "      <th>Huyện_Xã Tân Triều</th>\n",
              "      <th>Huyện_Xã Tả Thanh Oai</th>\n",
              "      <th>Huyện_Xã Tứ Hiệp</th>\n",
              "      <th>Huyện_Xã Uy Nỗ</th>\n",
              "      <th>Huyện_Xã Vân Canh</th>\n",
              "      <th>Huyện_Xã Vân Côn</th>\n",
              "      <th>Huyện_Xã Vân Nội</th>\n",
              "      <th>Huyện_Xã Võng La</th>\n",
              "      <th>Huyện_Xã Vĩnh Ngọc</th>\n",
              "      <th>Huyện_Xã Vĩnh Quỳnh</th>\n",
              "      <th>Huyện_Xã Vạn Phúc</th>\n",
              "      <th>Huyện_Xã Xuân Nộn</th>\n",
              "      <th>Huyện_Xã Yên Thường</th>\n",
              "      <th>Huyện_Xã Yên Viên</th>\n",
              "      <th>Huyện_Xã Đa Tốn</th>\n",
              "      <th>Huyện_Xã Đông Dư</th>\n",
              "      <th>Huyện_Xã Đông Hội</th>\n",
              "      <th>Huyện_Xã Đông La</th>\n",
              "      <th>Huyện_Xã Đông Mỹ</th>\n",
              "      <th>Huyện_Xã Đặng Xá</th>\n",
              "      <th>Huyện_Xã Đức Giang</th>\n",
              "      <th>Huyện_Xã Đức Thượng</th>\n",
              "      <th>Loại hình nhà ở_Nhà biệt thự</th>\n",
              "      <th>Loại hình nhà ở_Nhà mặt phố, mặt tiền</th>\n",
              "      <th>Loại hình nhà ở_Nhà ngõ, hẻm</th>\n",
              "      <th>Loại hình nhà ở_Nhà phố liền kề</th>\n",
              "      <th>Giá</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>73600.000000</td>\n",
              "      <td>73600.000000</td>\n",
              "      <td>73600.000000</td>\n",
              "      <td>73600.000000</td>\n",
              "      <td>73600.000000</td>\n",
              "      <td>73600.000000</td>\n",
              "      <td>73600.000000</td>\n",
              "      <td>73600.000000</td>\n",
              "      <td>73600.000000</td>\n",
              "      <td>73600.000000</td>\n",
              "      <td>73600.000000</td>\n",
              "      <td>73600.000000</td>\n",
              "      <td>73600.000000</td>\n",
              "      <td>73600.000000</td>\n",
              "      <td>73600.000000</td>\n",
              "      <td>73600.000000</td>\n",
              "      <td>73600.000000</td>\n",
              "      <td>73600.000000</td>\n",
              "      <td>73600.000000</td>\n",
              "      <td>73600.000000</td>\n",
              "      <td>73600.000000</td>\n",
              "      <td>73600.000000</td>\n",
              "      <td>73600.000000</td>\n",
              "      <td>73600.000000</td>\n",
              "      <td>73600.000000</td>\n",
              "      <td>73600.000000</td>\n",
              "      <td>73600.000000</td>\n",
              "      <td>73600.000000</td>\n",
              "      <td>73600.000000</td>\n",
              "      <td>73600.000000</td>\n",
              "      <td>73600.000000</td>\n",
              "      <td>73600.000000</td>\n",
              "      <td>73600.000000</td>\n",
              "      <td>73600.000000</td>\n",
              "      <td>73600.000000</td>\n",
              "      <td>73600.000000</td>\n",
              "      <td>73600.000000</td>\n",
              "      <td>73600.000000</td>\n",
              "      <td>73600.000000</td>\n",
              "      <td>73600.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>73600.000000</td>\n",
              "      <td>73600.000000</td>\n",
              "      <td>73600.000000</td>\n",
              "      <td>73600.000000</td>\n",
              "      <td>73600.000000</td>\n",
              "      <td>73600.000000</td>\n",
              "      <td>73600.000000</td>\n",
              "      <td>73600.000000</td>\n",
              "      <td>73600.000000</td>\n",
              "      <td>73600.000000</td>\n",
              "      <td>73600.000000</td>\n",
              "      <td>73600.000000</td>\n",
              "      <td>73600.000000</td>\n",
              "      <td>73600.000000</td>\n",
              "      <td>73600.000000</td>\n",
              "      <td>73600.000000</td>\n",
              "      <td>73600.000000</td>\n",
              "      <td>73600.000000</td>\n",
              "      <td>73600.000000</td>\n",
              "      <td>73600.000000</td>\n",
              "      <td>73600.000000</td>\n",
              "      <td>73600.000000</td>\n",
              "      <td>73600.000000</td>\n",
              "      <td>73600.000000</td>\n",
              "      <td>73600.000000</td>\n",
              "      <td>73600.000000</td>\n",
              "      <td>73600.000000</td>\n",
              "      <td>73600.000000</td>\n",
              "      <td>73600.000000</td>\n",
              "      <td>73600.000000</td>\n",
              "      <td>73600.000000</td>\n",
              "      <td>73600.000000</td>\n",
              "      <td>73600.000000</td>\n",
              "      <td>73600.000000</td>\n",
              "      <td>73600.000000</td>\n",
              "      <td>73600.000000</td>\n",
              "      <td>73600.000000</td>\n",
              "      <td>73600.000000</td>\n",
              "      <td>73600.000000</td>\n",
              "      <td>73600.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1.538547</td>\n",
              "      <td>3.743148</td>\n",
              "      <td>0.000041</td>\n",
              "      <td>0.002201</td>\n",
              "      <td>0.004891</td>\n",
              "      <td>0.000027</td>\n",
              "      <td>0.000014</td>\n",
              "      <td>0.000041</td>\n",
              "      <td>0.000557</td>\n",
              "      <td>0.014022</td>\n",
              "      <td>0.000014</td>\n",
              "      <td>0.000014</td>\n",
              "      <td>0.000149</td>\n",
              "      <td>0.000530</td>\n",
              "      <td>0.051957</td>\n",
              "      <td>0.019008</td>\n",
              "      <td>0.078967</td>\n",
              "      <td>0.129851</td>\n",
              "      <td>0.002962</td>\n",
              "      <td>0.144280</td>\n",
              "      <td>0.099402</td>\n",
              "      <td>0.051685</td>\n",
              "      <td>0.039620</td>\n",
              "      <td>0.164606</td>\n",
              "      <td>0.033030</td>\n",
              "      <td>0.162092</td>\n",
              "      <td>0.000041</td>\n",
              "      <td>0.000380</td>\n",
              "      <td>0.005734</td>\n",
              "      <td>0.000557</td>\n",
              "      <td>0.007418</td>\n",
              "      <td>0.016644</td>\n",
              "      <td>0.003777</td>\n",
              "      <td>0.010326</td>\n",
              "      <td>0.000870</td>\n",
              "      <td>0.003234</td>\n",
              "      <td>0.002079</td>\n",
              "      <td>0.001264</td>\n",
              "      <td>0.007228</td>\n",
              "      <td>0.004266</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000027</td>\n",
              "      <td>0.000231</td>\n",
              "      <td>0.001073</td>\n",
              "      <td>0.000014</td>\n",
              "      <td>0.000014</td>\n",
              "      <td>0.000014</td>\n",
              "      <td>0.000014</td>\n",
              "      <td>0.001155</td>\n",
              "      <td>0.003641</td>\n",
              "      <td>0.000014</td>\n",
              "      <td>0.000014</td>\n",
              "      <td>0.000014</td>\n",
              "      <td>0.000122</td>\n",
              "      <td>0.002853</td>\n",
              "      <td>0.001671</td>\n",
              "      <td>0.001141</td>\n",
              "      <td>0.000027</td>\n",
              "      <td>0.001535</td>\n",
              "      <td>0.000027</td>\n",
              "      <td>0.000027</td>\n",
              "      <td>0.000068</td>\n",
              "      <td>0.000027</td>\n",
              "      <td>0.000380</td>\n",
              "      <td>0.000014</td>\n",
              "      <td>0.000014</td>\n",
              "      <td>0.000014</td>\n",
              "      <td>0.000014</td>\n",
              "      <td>0.000041</td>\n",
              "      <td>0.000082</td>\n",
              "      <td>0.000014</td>\n",
              "      <td>0.000435</td>\n",
              "      <td>0.000109</td>\n",
              "      <td>0.000163</td>\n",
              "      <td>0.000027</td>\n",
              "      <td>0.000014</td>\n",
              "      <td>0.004103</td>\n",
              "      <td>0.172269</td>\n",
              "      <td>0.802079</td>\n",
              "      <td>0.021549</td>\n",
              "      <td>22.013370</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.260042</td>\n",
              "      <td>0.272356</td>\n",
              "      <td>0.006384</td>\n",
              "      <td>0.046864</td>\n",
              "      <td>0.069767</td>\n",
              "      <td>0.005213</td>\n",
              "      <td>0.003686</td>\n",
              "      <td>0.006384</td>\n",
              "      <td>0.023596</td>\n",
              "      <td>0.117581</td>\n",
              "      <td>0.003686</td>\n",
              "      <td>0.003686</td>\n",
              "      <td>0.012224</td>\n",
              "      <td>0.023013</td>\n",
              "      <td>0.221941</td>\n",
              "      <td>0.136554</td>\n",
              "      <td>0.269690</td>\n",
              "      <td>0.336141</td>\n",
              "      <td>0.054344</td>\n",
              "      <td>0.351376</td>\n",
              "      <td>0.299203</td>\n",
              "      <td>0.221391</td>\n",
              "      <td>0.195065</td>\n",
              "      <td>0.370827</td>\n",
              "      <td>0.178716</td>\n",
              "      <td>0.368538</td>\n",
              "      <td>0.006384</td>\n",
              "      <td>0.019501</td>\n",
              "      <td>0.075504</td>\n",
              "      <td>0.023596</td>\n",
              "      <td>0.085811</td>\n",
              "      <td>0.127934</td>\n",
              "      <td>0.061343</td>\n",
              "      <td>0.101092</td>\n",
              "      <td>0.029476</td>\n",
              "      <td>0.056774</td>\n",
              "      <td>0.045547</td>\n",
              "      <td>0.035525</td>\n",
              "      <td>0.084712</td>\n",
              "      <td>0.065178</td>\n",
              "      <td>...</td>\n",
              "      <td>0.005213</td>\n",
              "      <td>0.015196</td>\n",
              "      <td>0.032745</td>\n",
              "      <td>0.003686</td>\n",
              "      <td>0.003686</td>\n",
              "      <td>0.003686</td>\n",
              "      <td>0.003686</td>\n",
              "      <td>0.033964</td>\n",
              "      <td>0.060234</td>\n",
              "      <td>0.003686</td>\n",
              "      <td>0.003686</td>\n",
              "      <td>0.003686</td>\n",
              "      <td>0.011058</td>\n",
              "      <td>0.053340</td>\n",
              "      <td>0.040846</td>\n",
              "      <td>0.033764</td>\n",
              "      <td>0.005213</td>\n",
              "      <td>0.039153</td>\n",
              "      <td>0.005213</td>\n",
              "      <td>0.005213</td>\n",
              "      <td>0.008242</td>\n",
              "      <td>0.005213</td>\n",
              "      <td>0.019501</td>\n",
              "      <td>0.003686</td>\n",
              "      <td>0.003686</td>\n",
              "      <td>0.003686</td>\n",
              "      <td>0.003686</td>\n",
              "      <td>0.006384</td>\n",
              "      <td>0.009029</td>\n",
              "      <td>0.003686</td>\n",
              "      <td>0.020847</td>\n",
              "      <td>0.010425</td>\n",
              "      <td>0.012768</td>\n",
              "      <td>0.005213</td>\n",
              "      <td>0.003686</td>\n",
              "      <td>0.063926</td>\n",
              "      <td>0.377617</td>\n",
              "      <td>0.398435</td>\n",
              "      <td>0.145206</td>\n",
              "      <td>0.422286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.693147</td>\n",
              "      <td>3.049273</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>20.337574</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.386294</td>\n",
              "      <td>3.555348</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>21.734903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.609438</td>\n",
              "      <td>3.713572</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>21.976029</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.609438</td>\n",
              "      <td>3.931826</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>22.249379</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2.484907</td>\n",
              "      <td>4.605170</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>23.693682</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 265 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Số phòng ngủ  ...           Giá\n",
              "count  73600.000000  ...  73600.000000\n",
              "mean       1.538547  ...     22.013370\n",
              "std        0.260042  ...      0.422286\n",
              "min        0.693147  ...     20.337574\n",
              "25%        1.386294  ...     21.734903\n",
              "50%        1.609438  ...     21.976029\n",
              "75%        1.609438  ...     22.249379\n",
              "max        2.484907  ...     23.693682\n",
              "\n",
              "[8 rows x 265 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 216
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8mOwXwzaJoT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "01db8910-859b-4a3f-de14-65f9784ae02f"
      },
      "source": [
        "X = res.drop('Giá', axis=1).to_numpy()\n",
        "Y = res['Giá'].to_numpy()\n",
        "\n",
        "from sklearn import preprocessing\n",
        "\n",
        "scaler = preprocessing.RobustScaler()\n",
        "scaler.fit(X)\n",
        "X = scaler.transform(X)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)\n",
        "X_val, X_test, Y_val, Y_test = train_test_split(X_test, Y_test, test_size=0.5)\n",
        "\n",
        "print(np.shape(X_val))"
      ],
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7360, 264)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcE82RJXFldX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# str_list = []\n",
        "# for colname, colvalue in res.iteritems():\n",
        "#     if type(colvalue[1]) == str:\n",
        "#          str_list.append(colname)\n",
        "# num_list = res.columns.difference(str_list) \n",
        "# house_num = res[num_list]\n",
        "# f, ax = plt.subplots(figsize=(16, 12))\n",
        "# plt.title('Pearson Correlation of features')\n",
        "# sns.heatmap(house_num.astype(float).corr(),linewidths=0.25,vmax=1.0, square=True, cmap=\"cubehelix\", linecolor='k', annot=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLF3LA09BGck",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import xgboost\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.linear_model import RidgeCV\n",
        "from sklearn.svm import SVR\n",
        "from mlxtend.regressor import StackingCVRegressor\n",
        "import lightgbm as lgb\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.model_selection import KFold"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZ5OIVTI8BJ6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "d87beeef-965c-40df-e5a2-35b884d4f5e3"
      },
      "source": [
        "param_init = {\n",
        "    \"max_depth\": 5, \n",
        "    \"n_estimators\": 3000, \n",
        "    \"learning_rate\": 0.25, \n",
        "    \"subsample\": 0.5,\n",
        "    \"colsample_bytree\": 0.7,\n",
        "    \"min_child_weight\": 1.5,\n",
        "    \"reg_alpha\": 0.75,\n",
        "    \"reg_lambda\": 0.4,\n",
        "    \"seed\": 42,\n",
        "}\n",
        "\n",
        "param_fit = {\n",
        "    \"eval_metric\": \"rmse\",\n",
        "    \"early_stopping_rounds\": 500,\n",
        "    \"verbose\": 200,\n",
        "    \"eval_set\": [(X_val, Y_val)]\n",
        "}\n",
        "\n",
        "xgb_model = xgboost.XGBRegressor(**param_init)\n",
        "xgb_model.fit(X_train, Y_train, **param_fit)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[23:34:40] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[0]\tvalidation_0-rmse:16.1395\n",
            "Will train until validation_0-rmse hasn't improved in 500 rounds.\n",
            "[200]\tvalidation_0-rmse:0.24212\n",
            "[400]\tvalidation_0-rmse:0.240322\n",
            "[600]\tvalidation_0-rmse:0.240051\n",
            "[800]\tvalidation_0-rmse:0.239709\n",
            "[1000]\tvalidation_0-rmse:0.239607\n",
            "[1200]\tvalidation_0-rmse:0.23986\n",
            "Stopping. Best iteration:\n",
            "[831]\tvalidation_0-rmse:0.239419\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "             colsample_bynode=1, colsample_bytree=0.7, gamma=0,\n",
              "             importance_type='gain', learning_rate=0.25, max_delta_step=0,\n",
              "             max_depth=5, min_child_weight=1.5, missing=None, n_estimators=3000,\n",
              "             n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
              "             reg_alpha=0.75, reg_lambda=0.4, scale_pos_weight=1, seed=42,\n",
              "             silent=None, subsample=0.5, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nr8ojaGUqrxV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c78d2011-5af8-40d7-9c4c-ccada0a2f99b"
      },
      "source": [
        "Y_pred_xgb = xgb_model.predict(X_test)\n",
        "(1- (abs(np.expm1(Y_pred_xgb) - np.expm1(Y_test)) / np.expm1(Y_test)).mean()) * 100"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "81.37975787905678"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HPXSBb_CLCQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "477c2a87-43b4-4ae1-d64d-2e35ffeb7b41"
      },
      "source": [
        "rf = RandomForestRegressor(n_estimators=2000,\n",
        "                          max_depth=15,\n",
        "                          min_samples_split=5,\n",
        "                          min_samples_leaf=5,\n",
        "                          max_features=None,\n",
        "                          oob_score=True,\n",
        "                          random_state=42)\n",
        "rf.fit(X_train, Y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
              "                      max_depth=15, max_features=None, max_leaf_nodes=None,\n",
              "                      max_samples=None, min_impurity_decrease=0.0,\n",
              "                      min_impurity_split=None, min_samples_leaf=5,\n",
              "                      min_samples_split=5, min_weight_fraction_leaf=0.0,\n",
              "                      n_estimators=2000, n_jobs=None, oob_score=True,\n",
              "                      random_state=42, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chRuOW5bCzhi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "188cf0e2-83dd-4e0e-bdf6-363d2e04dd3b"
      },
      "source": [
        "Y_pred_rf = rf.predict(X_test)\n",
        "(1- (abs(np.expm1(Y_pred_rf) - np.expm1(Y_test)) / np.expm1(Y_test)).mean()) * 100"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "80.460693478554"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sl2LqxmBDL0P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "0a6b3dc8-a772-4613-ef3d-bb3b076d5cd1"
      },
      "source": [
        "gbr = GradientBoostingRegressor(n_estimators=3000,\n",
        "                                learning_rate=0.25,\n",
        "                                max_depth=5,\n",
        "                                max_features='sqrt',\n",
        "                                min_samples_leaf=15,\n",
        "                                min_samples_split=10,\n",
        "                                loss='huber',\n",
        "                                random_state=42)\n",
        "gbr.fit(X_train, Y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
              "                          init=None, learning_rate=0.25, loss='huber',\n",
              "                          max_depth=5, max_features='sqrt', max_leaf_nodes=None,\n",
              "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                          min_samples_leaf=15, min_samples_split=10,\n",
              "                          min_weight_fraction_leaf=0.0, n_estimators=3000,\n",
              "                          n_iter_no_change=None, presort='deprecated',\n",
              "                          random_state=42, subsample=1.0, tol=0.0001,\n",
              "                          validation_fraction=0.1, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uu6w5yoYDV3t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "906602b9-2a69-4d31-da34-0e4aad496aed"
      },
      "source": [
        "Y_pred_gbr = gbr.predict(X_test)\n",
        "(1- (abs(np.expm1(Y_pred_gbr) - np.expm1(Y_test)) / np.expm1(Y_test)).mean()) * 100"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "81.52299834922161"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jxTQmVjMnci",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "9ae15eab-b92d-4a0c-9cba-e729ab1f7400"
      },
      "source": [
        "ridge_alphas = [1e-15, 1e-10, 1e-8, 9e-4, 7e-4, 5e-4, 3e-4, 1e-4, 1e-3, 5e-2, 1e-2, 0.1, 0.3, 1, 3, 5, 10, 15, 18, 20, 30, 50, 75, 100]\n",
        "kf = KFold(n_splits=12, random_state=42, shuffle=True)\n",
        "ridge = RidgeCV(ridge_alphas, cv=kf)\n",
        "ridge.fit(X_train, Y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RidgeCV(alphas=array([1.0e-15, 1.0e-10, 1.0e-08, 9.0e-04, 7.0e-04, 5.0e-04, 3.0e-04,\n",
              "       1.0e-04, 1.0e-03, 5.0e-02, 1.0e-02, 1.0e-01, 3.0e-01, 1.0e+00,\n",
              "       3.0e+00, 5.0e+00, 1.0e+01, 1.5e+01, 1.8e+01, 2.0e+01, 3.0e+01,\n",
              "       5.0e+01, 7.5e+01, 1.0e+02]),\n",
              "        cv=KFold(n_splits=12, random_state=42, shuffle=True),\n",
              "        fit_intercept=True, gcv_mode=None, normalize=False, scoring=None,\n",
              "        store_cv_values=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXPPbtftNIy8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "efe5b007-c684-4679-e68f-d77e2de7320d"
      },
      "source": [
        "Y_pred_ridge = ridge.predict(X_test)\n",
        "(1- (abs(np.expm1(Y_pred_ridge) - np.expm1(Y_test)) / np.expm1(Y_test)).mean()) * 100"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "80.1008470856304"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eh3pEZsIYzyL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_pred_final = (0.25 * np.expm1(xgb_model.predict(X_test)) +\n",
        "                0.05 * np.expm1(rf.predict(X_test)) +\n",
        "                0.65 * np.expm1(gbr.predict(X_test)) +\n",
        "                0.05 * np.expm1(ridge.predict(X_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nn5XH3CocRCf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e050eb41-817f-4b81-c802-0808e794ea03"
      },
      "source": [
        "Accu = (1- (abs(Y_pred_final - np.expm1(Y_test)) / np.expm1(Y_test)).mean()) * 100\n",
        "print(\"Accuracy: {}\".format(Accu))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 81.56871725962134\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4JKJAv9cRZs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_pred_final = [[i] for i in Y_pred_final]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pnfu4X_MfRTk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_pred_final = pd.DataFrame(Y_pred_final, columns=['Giá'], index=range(1, len(Y_pred_final)+1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FoYkezfDExd9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.layers import Dropout, Dense\n",
        "from keras import Sequential\n",
        "from keras.optimizers import SGD, Adam\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.initializers import he_normal\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(265, activation='tanh',\n",
        "                kernel_initializer=he_normal(seed=None),\n",
        "                input_dim=264))\n",
        "\n",
        "model.add(Dense(180, kernel_initializer=he_normal(seed=None),\n",
        "                activation='tanh'))\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Dense(150, kernel_initializer=he_normal(seed=None),\n",
        "                activation='tanh'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dense(100, kernel_initializer=he_normal(seed=None),\n",
        "                activation='tanh'))\n",
        "\n",
        "model.add(Dense(60, kernel_initializer=he_normal(seed=None),\n",
        "                activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dense(20, kernel_initializer=he_normal(seed=None),\n",
        "                activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dense(1, kernel_initializer=he_normal(seed=None),\n",
        "                activation='elu'))\n",
        "# sgd = SGD(lr=0.25)\n",
        "model.compile(optimizer=SGD(lr=0.05), loss='mae')\n",
        "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=50)\n"
      ],
      "execution_count": 220,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bulHfY573_az",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "28b1ec09-2a48-4c30-9f65-bb0a623eae3a"
      },
      "source": [
        "history = model.fit(X_train, Y_train, epochs=500,\n",
        "                    validation_data=(X_val, Y_val))"
      ],
      "execution_count": 231,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1781 - val_loss: 0.1788\n",
            "Epoch 2/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1783 - val_loss: 0.1801\n",
            "Epoch 3/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1776 - val_loss: 0.1824\n",
            "Epoch 4/500\n",
            "1840/1840 [==============================] - 5s 2ms/step - loss: 0.1775 - val_loss: 0.1808\n",
            "Epoch 5/500\n",
            "1840/1840 [==============================] - 5s 2ms/step - loss: 0.1784 - val_loss: 0.1805\n",
            "Epoch 6/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1776 - val_loss: 0.1808\n",
            "Epoch 7/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1783 - val_loss: 0.1852\n",
            "Epoch 8/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1777 - val_loss: 0.1779\n",
            "Epoch 9/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1774 - val_loss: 0.1798\n",
            "Epoch 10/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1788 - val_loss: 0.1786\n",
            "Epoch 11/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1783 - val_loss: 0.1771\n",
            "Epoch 12/500\n",
            "1840/1840 [==============================] - 5s 2ms/step - loss: 0.1779 - val_loss: 0.1870\n",
            "Epoch 13/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1787 - val_loss: 0.1779\n",
            "Epoch 14/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1779 - val_loss: 0.1777\n",
            "Epoch 15/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1775 - val_loss: 0.1769\n",
            "Epoch 16/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1781 - val_loss: 0.1811\n",
            "Epoch 17/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1778 - val_loss: 0.1773\n",
            "Epoch 18/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1778 - val_loss: 0.1801\n",
            "Epoch 19/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1783 - val_loss: 0.1801\n",
            "Epoch 20/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1783 - val_loss: 0.1795\n",
            "Epoch 21/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1777 - val_loss: 0.1776\n",
            "Epoch 22/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1790 - val_loss: 0.1782\n",
            "Epoch 23/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1779 - val_loss: 0.1822\n",
            "Epoch 24/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1776 - val_loss: 0.1795\n",
            "Epoch 25/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1780 - val_loss: 0.1780\n",
            "Epoch 26/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1770 - val_loss: 0.1828\n",
            "Epoch 27/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1784 - val_loss: 0.1777\n",
            "Epoch 28/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1775 - val_loss: 0.1806\n",
            "Epoch 29/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1790 - val_loss: 0.1778\n",
            "Epoch 30/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1769 - val_loss: 0.1789\n",
            "Epoch 31/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1777 - val_loss: 0.1779\n",
            "Epoch 32/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1773 - val_loss: 0.1806\n",
            "Epoch 33/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1771 - val_loss: 0.1787\n",
            "Epoch 34/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1780 - val_loss: 0.1798\n",
            "Epoch 35/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1778 - val_loss: 0.1790\n",
            "Epoch 36/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1785 - val_loss: 0.1822\n",
            "Epoch 37/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1769 - val_loss: 0.1793\n",
            "Epoch 38/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1780 - val_loss: 0.1813\n",
            "Epoch 39/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1777 - val_loss: 0.1786\n",
            "Epoch 40/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1776 - val_loss: 0.1801\n",
            "Epoch 41/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1777 - val_loss: 0.1799\n",
            "Epoch 42/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1773 - val_loss: 0.1799\n",
            "Epoch 43/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1779 - val_loss: 0.1802\n",
            "Epoch 44/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1777 - val_loss: 0.1789\n",
            "Epoch 45/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1771 - val_loss: 0.1786\n",
            "Epoch 46/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1772 - val_loss: 0.1797\n",
            "Epoch 47/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1780 - val_loss: 0.1877\n",
            "Epoch 48/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1778 - val_loss: 0.1807\n",
            "Epoch 49/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1780 - val_loss: 0.1807\n",
            "Epoch 50/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1772 - val_loss: 0.1785\n",
            "Epoch 51/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1782 - val_loss: 0.1800\n",
            "Epoch 52/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1766 - val_loss: 0.1797\n",
            "Epoch 53/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1778 - val_loss: 0.1845\n",
            "Epoch 54/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1771 - val_loss: 0.1804\n",
            "Epoch 55/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1772 - val_loss: 0.1857\n",
            "Epoch 56/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1776 - val_loss: 0.1804\n",
            "Epoch 57/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1769 - val_loss: 0.1930\n",
            "Epoch 58/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1768 - val_loss: 0.1777\n",
            "Epoch 59/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1768 - val_loss: 0.1785\n",
            "Epoch 60/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1771 - val_loss: 0.1836\n",
            "Epoch 61/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1773 - val_loss: 0.1816\n",
            "Epoch 62/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1772 - val_loss: 0.1781\n",
            "Epoch 63/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1777 - val_loss: 0.1793\n",
            "Epoch 64/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1777 - val_loss: 0.1812\n",
            "Epoch 65/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1772 - val_loss: 0.1779\n",
            "Epoch 66/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1769 - val_loss: 0.1784\n",
            "Epoch 67/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1765 - val_loss: 0.1822\n",
            "Epoch 68/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1767 - val_loss: 0.1802\n",
            "Epoch 69/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1766 - val_loss: 0.1828\n",
            "Epoch 70/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1774 - val_loss: 0.1794\n",
            "Epoch 71/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1771 - val_loss: 0.1781\n",
            "Epoch 72/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1765 - val_loss: 0.1776\n",
            "Epoch 73/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1780 - val_loss: 0.1804\n",
            "Epoch 74/500\n",
            "1840/1840 [==============================] - 5s 2ms/step - loss: 0.1775 - val_loss: 0.1787\n",
            "Epoch 75/500\n",
            "1840/1840 [==============================] - 5s 2ms/step - loss: 0.1776 - val_loss: 0.1849\n",
            "Epoch 76/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1772 - val_loss: 0.1795\n",
            "Epoch 77/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1763 - val_loss: 0.1769\n",
            "Epoch 78/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1770 - val_loss: 0.1854\n",
            "Epoch 79/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1767 - val_loss: 0.1806\n",
            "Epoch 80/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1766 - val_loss: 0.1795\n",
            "Epoch 81/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1776 - val_loss: 0.1781\n",
            "Epoch 82/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1769 - val_loss: 0.1794\n",
            "Epoch 83/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1770 - val_loss: 0.1836\n",
            "Epoch 84/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1758 - val_loss: 0.1833\n",
            "Epoch 85/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1771 - val_loss: 0.1798\n",
            "Epoch 86/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1767 - val_loss: 0.1858\n",
            "Epoch 87/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1772 - val_loss: 0.1810\n",
            "Epoch 88/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1774 - val_loss: 0.1791\n",
            "Epoch 89/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1759 - val_loss: 0.1802\n",
            "Epoch 90/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1770 - val_loss: 0.1783\n",
            "Epoch 91/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1764 - val_loss: 0.1785\n",
            "Epoch 92/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1769 - val_loss: 0.1777\n",
            "Epoch 93/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1768 - val_loss: 0.1805\n",
            "Epoch 94/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1774 - val_loss: 0.1788\n",
            "Epoch 95/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1762 - val_loss: 0.1801\n",
            "Epoch 96/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1768 - val_loss: 0.1846\n",
            "Epoch 97/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1768 - val_loss: 0.1794\n",
            "Epoch 98/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1766 - val_loss: 0.1873\n",
            "Epoch 99/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1770 - val_loss: 0.1783\n",
            "Epoch 100/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1757 - val_loss: 0.1775\n",
            "Epoch 101/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1760 - val_loss: 0.1783\n",
            "Epoch 102/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1763 - val_loss: 0.1797\n",
            "Epoch 103/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1775 - val_loss: 0.1786\n",
            "Epoch 104/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1764 - val_loss: 0.1781\n",
            "Epoch 105/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1771 - val_loss: 0.1800\n",
            "Epoch 106/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1774 - val_loss: 0.1808\n",
            "Epoch 107/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1770 - val_loss: 0.1851\n",
            "Epoch 108/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1771 - val_loss: 0.1821\n",
            "Epoch 109/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1767 - val_loss: 0.1785\n",
            "Epoch 110/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1759 - val_loss: 0.1776\n",
            "Epoch 111/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1767 - val_loss: 0.1810\n",
            "Epoch 112/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1766 - val_loss: 0.1882\n",
            "Epoch 113/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1762 - val_loss: 0.1805\n",
            "Epoch 114/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1763 - val_loss: 0.1821\n",
            "Epoch 115/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1768 - val_loss: 0.1802\n",
            "Epoch 116/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1753 - val_loss: 0.1813\n",
            "Epoch 117/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1769 - val_loss: 0.1835\n",
            "Epoch 118/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1757 - val_loss: 0.1798\n",
            "Epoch 119/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1765 - val_loss: 0.1806\n",
            "Epoch 120/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1770 - val_loss: 0.1800\n",
            "Epoch 121/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1762 - val_loss: 0.1813\n",
            "Epoch 122/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1763 - val_loss: 0.1812\n",
            "Epoch 123/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1766 - val_loss: 0.1798\n",
            "Epoch 124/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1766 - val_loss: 0.1784\n",
            "Epoch 125/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1762 - val_loss: 0.1798\n",
            "Epoch 126/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1767 - val_loss: 0.1791\n",
            "Epoch 127/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1762 - val_loss: 0.1780\n",
            "Epoch 128/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1761 - val_loss: 0.1797\n",
            "Epoch 129/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1765 - val_loss: 0.1810\n",
            "Epoch 130/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1762 - val_loss: 0.1808\n",
            "Epoch 131/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1759 - val_loss: 0.1780\n",
            "Epoch 132/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1761 - val_loss: 0.1796\n",
            "Epoch 133/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1755 - val_loss: 0.1838\n",
            "Epoch 134/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1757 - val_loss: 0.1785\n",
            "Epoch 135/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1757 - val_loss: 0.1814\n",
            "Epoch 136/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1767 - val_loss: 0.1799\n",
            "Epoch 137/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1763 - val_loss: 0.1781\n",
            "Epoch 138/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1766 - val_loss: 0.1784\n",
            "Epoch 139/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1762 - val_loss: 0.1799\n",
            "Epoch 140/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1749 - val_loss: 0.1790\n",
            "Epoch 141/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1764 - val_loss: 0.1868\n",
            "Epoch 142/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1759 - val_loss: 0.1783\n",
            "Epoch 143/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1754 - val_loss: 0.1789\n",
            "Epoch 144/500\n",
            "1840/1840 [==============================] - 5s 2ms/step - loss: 0.1761 - val_loss: 0.1950\n",
            "Epoch 145/500\n",
            "1840/1840 [==============================] - 5s 2ms/step - loss: 0.1758 - val_loss: 0.1795\n",
            "Epoch 146/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1762 - val_loss: 0.1821\n",
            "Epoch 147/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1767 - val_loss: 0.1860\n",
            "Epoch 148/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1765 - val_loss: 0.1812\n",
            "Epoch 149/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1759 - val_loss: 0.1819\n",
            "Epoch 150/500\n",
            "1840/1840 [==============================] - 5s 2ms/step - loss: 0.1759 - val_loss: 0.1795\n",
            "Epoch 151/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1752 - val_loss: 0.1786\n",
            "Epoch 152/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1763 - val_loss: 0.1806\n",
            "Epoch 153/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1759 - val_loss: 0.1805\n",
            "Epoch 154/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1772 - val_loss: 0.1809\n",
            "Epoch 155/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1754 - val_loss: 0.1781\n",
            "Epoch 156/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1759 - val_loss: 0.1783\n",
            "Epoch 157/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1760 - val_loss: 0.1796\n",
            "Epoch 158/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1751 - val_loss: 0.1815\n",
            "Epoch 159/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1750 - val_loss: 0.1794\n",
            "Epoch 160/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1761 - val_loss: 0.1802\n",
            "Epoch 161/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1758 - val_loss: 0.1801\n",
            "Epoch 162/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1760 - val_loss: 0.1804\n",
            "Epoch 163/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1761 - val_loss: 0.1788\n",
            "Epoch 164/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1767 - val_loss: 0.1791\n",
            "Epoch 165/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1762 - val_loss: 0.1813\n",
            "Epoch 166/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1760 - val_loss: 0.1844\n",
            "Epoch 167/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1759 - val_loss: 0.1785\n",
            "Epoch 168/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1749 - val_loss: 0.1850\n",
            "Epoch 169/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1756 - val_loss: 0.1809\n",
            "Epoch 170/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1760 - val_loss: 0.1789\n",
            "Epoch 171/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1758 - val_loss: 0.1806\n",
            "Epoch 172/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1754 - val_loss: 0.1790\n",
            "Epoch 173/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1764 - val_loss: 0.1796\n",
            "Epoch 174/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1765 - val_loss: 0.1790\n",
            "Epoch 175/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1744 - val_loss: 0.1819\n",
            "Epoch 176/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1756 - val_loss: 0.1787\n",
            "Epoch 177/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1751 - val_loss: 0.1784\n",
            "Epoch 178/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1749 - val_loss: 0.1809\n",
            "Epoch 179/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1746 - val_loss: 0.1778\n",
            "Epoch 180/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1746 - val_loss: 0.1803\n",
            "Epoch 181/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1763 - val_loss: 0.1911\n",
            "Epoch 182/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1755 - val_loss: 0.1802\n",
            "Epoch 183/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1758 - val_loss: 0.1850\n",
            "Epoch 184/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1750 - val_loss: 0.1795\n",
            "Epoch 185/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1755 - val_loss: 0.1795\n",
            "Epoch 186/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1758 - val_loss: 0.1783\n",
            "Epoch 187/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1750 - val_loss: 0.1816\n",
            "Epoch 188/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1751 - val_loss: 0.1779\n",
            "Epoch 189/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1755 - val_loss: 0.1820\n",
            "Epoch 190/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1747 - val_loss: 0.1802\n",
            "Epoch 191/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1742 - val_loss: 0.1897\n",
            "Epoch 192/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1762 - val_loss: 0.1851\n",
            "Epoch 193/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1751 - val_loss: 0.1794\n",
            "Epoch 194/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1759 - val_loss: 0.1847\n",
            "Epoch 195/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1749 - val_loss: 0.1788\n",
            "Epoch 196/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1762 - val_loss: 0.1786\n",
            "Epoch 197/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1759 - val_loss: 0.1831\n",
            "Epoch 198/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1754 - val_loss: 0.1769\n",
            "Epoch 199/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1760 - val_loss: 0.1774\n",
            "Epoch 200/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1746 - val_loss: 0.1787\n",
            "Epoch 201/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1746 - val_loss: 0.1816\n",
            "Epoch 202/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1753 - val_loss: 0.1792\n",
            "Epoch 203/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1751 - val_loss: 0.1849\n",
            "Epoch 204/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1745 - val_loss: 0.1811\n",
            "Epoch 205/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1750 - val_loss: 0.1799\n",
            "Epoch 206/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1747 - val_loss: 0.1795\n",
            "Epoch 207/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1746 - val_loss: 0.1791\n",
            "Epoch 208/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1750 - val_loss: 0.1783\n",
            "Epoch 209/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1755 - val_loss: 0.1801\n",
            "Epoch 210/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1754 - val_loss: 0.1785\n",
            "Epoch 211/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1750 - val_loss: 0.1823\n",
            "Epoch 212/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1759 - val_loss: 0.1813\n",
            "Epoch 213/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1744 - val_loss: 0.1794\n",
            "Epoch 214/500\n",
            "1840/1840 [==============================] - 5s 2ms/step - loss: 0.1748 - val_loss: 0.1778\n",
            "Epoch 215/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1751 - val_loss: 0.1842\n",
            "Epoch 216/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1757 - val_loss: 0.1801\n",
            "Epoch 217/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1749 - val_loss: 0.1798\n",
            "Epoch 218/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1748 - val_loss: 0.1856\n",
            "Epoch 219/500\n",
            "1840/1840 [==============================] - 5s 2ms/step - loss: 0.1754 - val_loss: 0.1822\n",
            "Epoch 220/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1754 - val_loss: 0.1789\n",
            "Epoch 221/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1744 - val_loss: 0.1796\n",
            "Epoch 222/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1748 - val_loss: 0.1810\n",
            "Epoch 223/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1746 - val_loss: 0.1781\n",
            "Epoch 224/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1745 - val_loss: 0.1803\n",
            "Epoch 225/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1748 - val_loss: 0.1787\n",
            "Epoch 226/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1749 - val_loss: 0.1797\n",
            "Epoch 227/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1748 - val_loss: 0.1843\n",
            "Epoch 228/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1750 - val_loss: 0.1800\n",
            "Epoch 229/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1749 - val_loss: 0.1816\n",
            "Epoch 230/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1747 - val_loss: 0.1828\n",
            "Epoch 231/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1750 - val_loss: 0.1779\n",
            "Epoch 232/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1750 - val_loss: 0.1806\n",
            "Epoch 233/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1743 - val_loss: 0.1798\n",
            "Epoch 234/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1747 - val_loss: 0.1791\n",
            "Epoch 235/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1748 - val_loss: 0.1794\n",
            "Epoch 236/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1743 - val_loss: 0.1777\n",
            "Epoch 237/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1748 - val_loss: 0.1850\n",
            "Epoch 238/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1754 - val_loss: 0.1796\n",
            "Epoch 239/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1745 - val_loss: 0.1791\n",
            "Epoch 240/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1747 - val_loss: 0.1789\n",
            "Epoch 241/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1743 - val_loss: 0.1805\n",
            "Epoch 242/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1750 - val_loss: 0.1829\n",
            "Epoch 243/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1748 - val_loss: 0.1787\n",
            "Epoch 244/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1743 - val_loss: 0.1818\n",
            "Epoch 245/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1748 - val_loss: 0.1791\n",
            "Epoch 246/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1750 - val_loss: 0.1809\n",
            "Epoch 247/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1747 - val_loss: 0.1782\n",
            "Epoch 248/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1749 - val_loss: 0.1802\n",
            "Epoch 249/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1748 - val_loss: 0.1796\n",
            "Epoch 250/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1751 - val_loss: 0.1787\n",
            "Epoch 251/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1744 - val_loss: 0.1788\n",
            "Epoch 252/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1746 - val_loss: 0.1821\n",
            "Epoch 253/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1745 - val_loss: 0.1853\n",
            "Epoch 254/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1741 - val_loss: 0.1925\n",
            "Epoch 255/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1741 - val_loss: 0.1804\n",
            "Epoch 256/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1747 - val_loss: 0.1790\n",
            "Epoch 257/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1744 - val_loss: 0.1866\n",
            "Epoch 258/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1745 - val_loss: 0.1775\n",
            "Epoch 259/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1747 - val_loss: 0.1932\n",
            "Epoch 260/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1743 - val_loss: 0.1801\n",
            "Epoch 261/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1747 - val_loss: 0.1785\n",
            "Epoch 262/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1739 - val_loss: 0.1786\n",
            "Epoch 263/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1739 - val_loss: 0.1809\n",
            "Epoch 264/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1744 - val_loss: 0.1794\n",
            "Epoch 265/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1749 - val_loss: 0.1816\n",
            "Epoch 266/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1748 - val_loss: 0.1800\n",
            "Epoch 267/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1745 - val_loss: 0.1799\n",
            "Epoch 268/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1749 - val_loss: 0.1801\n",
            "Epoch 269/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1751 - val_loss: 0.1795\n",
            "Epoch 270/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1748 - val_loss: 0.1804\n",
            "Epoch 271/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1737 - val_loss: 0.1783\n",
            "Epoch 272/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1745 - val_loss: 0.1793\n",
            "Epoch 273/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1751 - val_loss: 0.1794\n",
            "Epoch 274/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1749 - val_loss: 0.1843\n",
            "Epoch 275/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1744 - val_loss: 0.1792\n",
            "Epoch 276/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1743 - val_loss: 0.1801\n",
            "Epoch 277/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1743 - val_loss: 0.1794\n",
            "Epoch 278/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1749 - val_loss: 0.1778\n",
            "Epoch 279/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1742 - val_loss: 0.1797\n",
            "Epoch 280/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1747 - val_loss: 0.1811\n",
            "Epoch 281/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1744 - val_loss: 0.1844\n",
            "Epoch 282/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1743 - val_loss: 0.1791\n",
            "Epoch 283/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1747 - val_loss: 0.1800\n",
            "Epoch 284/500\n",
            "1840/1840 [==============================] - 5s 2ms/step - loss: 0.1745 - val_loss: 0.1808\n",
            "Epoch 285/500\n",
            "1840/1840 [==============================] - 5s 2ms/step - loss: 0.1734 - val_loss: 0.1786\n",
            "Epoch 286/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1738 - val_loss: 0.1821\n",
            "Epoch 287/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1753 - val_loss: 0.1795\n",
            "Epoch 288/500\n",
            "1840/1840 [==============================] - 5s 2ms/step - loss: 0.1735 - val_loss: 0.1784\n",
            "Epoch 289/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1741 - val_loss: 0.1811\n",
            "Epoch 290/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1748 - val_loss: 0.1782\n",
            "Epoch 291/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1738 - val_loss: 0.1815\n",
            "Epoch 292/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1741 - val_loss: 0.1782\n",
            "Epoch 293/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1738 - val_loss: 0.1801\n",
            "Epoch 294/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1734 - val_loss: 0.1811\n",
            "Epoch 295/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1736 - val_loss: 0.1797\n",
            "Epoch 296/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1741 - val_loss: 0.1830\n",
            "Epoch 297/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1739 - val_loss: 0.1805\n",
            "Epoch 298/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1739 - val_loss: 0.1810\n",
            "Epoch 299/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1742 - val_loss: 0.1844\n",
            "Epoch 300/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1732 - val_loss: 0.1850\n",
            "Epoch 301/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1741 - val_loss: 0.1821\n",
            "Epoch 302/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1746 - val_loss: 0.1790\n",
            "Epoch 303/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1742 - val_loss: 0.1831\n",
            "Epoch 304/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1751 - val_loss: 0.1785\n",
            "Epoch 305/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1744 - val_loss: 0.1808\n",
            "Epoch 306/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1742 - val_loss: 0.1881\n",
            "Epoch 307/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1744 - val_loss: 0.1804\n",
            "Epoch 308/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1729 - val_loss: 0.1813\n",
            "Epoch 309/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1747 - val_loss: 0.1793\n",
            "Epoch 310/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1738 - val_loss: 0.1788\n",
            "Epoch 311/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1741 - val_loss: 0.1807\n",
            "Epoch 312/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1737 - val_loss: 0.1783\n",
            "Epoch 313/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1741 - val_loss: 0.1803\n",
            "Epoch 314/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1736 - val_loss: 0.1792\n",
            "Epoch 315/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1736 - val_loss: 0.1797\n",
            "Epoch 316/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1740 - val_loss: 0.1804\n",
            "Epoch 317/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1741 - val_loss: 0.1885\n",
            "Epoch 318/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1739 - val_loss: 0.1796\n",
            "Epoch 319/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1732 - val_loss: 0.1791\n",
            "Epoch 320/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1737 - val_loss: 0.1798\n",
            "Epoch 321/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1735 - val_loss: 0.1771\n",
            "Epoch 322/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1734 - val_loss: 0.1784\n",
            "Epoch 323/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1738 - val_loss: 0.1831\n",
            "Epoch 324/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1743 - val_loss: 0.1815\n",
            "Epoch 325/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1739 - val_loss: 0.1776\n",
            "Epoch 326/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1731 - val_loss: 0.1804\n",
            "Epoch 327/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1727 - val_loss: 0.1845\n",
            "Epoch 328/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1742 - val_loss: 0.1794\n",
            "Epoch 329/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1741 - val_loss: 0.1784\n",
            "Epoch 330/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1741 - val_loss: 0.1774\n",
            "Epoch 331/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1743 - val_loss: 0.1801\n",
            "Epoch 332/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1739 - val_loss: 0.1800\n",
            "Epoch 333/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1734 - val_loss: 0.1802\n",
            "Epoch 334/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1738 - val_loss: 0.1811\n",
            "Epoch 335/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1741 - val_loss: 0.1802\n",
            "Epoch 336/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1735 - val_loss: 0.1803\n",
            "Epoch 337/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1734 - val_loss: 0.1821\n",
            "Epoch 338/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1736 - val_loss: 0.1798\n",
            "Epoch 339/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1735 - val_loss: 0.1832\n",
            "Epoch 340/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1739 - val_loss: 0.1829\n",
            "Epoch 341/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1740 - val_loss: 0.1772\n",
            "Epoch 342/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1733 - val_loss: 0.1806\n",
            "Epoch 343/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1736 - val_loss: 0.1830\n",
            "Epoch 344/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1734 - val_loss: 0.1853\n",
            "Epoch 345/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1739 - val_loss: 0.1803\n",
            "Epoch 346/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1731 - val_loss: 0.1786\n",
            "Epoch 347/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1732 - val_loss: 0.1784\n",
            "Epoch 348/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1737 - val_loss: 0.1789\n",
            "Epoch 349/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1733 - val_loss: 0.1840\n",
            "Epoch 350/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1736 - val_loss: 0.1801\n",
            "Epoch 351/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1734 - val_loss: 0.1800\n",
            "Epoch 352/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1733 - val_loss: 0.1820\n",
            "Epoch 353/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1730 - val_loss: 0.1926\n",
            "Epoch 354/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1742 - val_loss: 0.1782\n",
            "Epoch 355/500\n",
            "1840/1840 [==============================] - 5s 2ms/step - loss: 0.1732 - val_loss: 0.1888\n",
            "Epoch 356/500\n",
            "1840/1840 [==============================] - 5s 2ms/step - loss: 0.1731 - val_loss: 0.1812\n",
            "Epoch 357/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1735 - val_loss: 0.1781\n",
            "Epoch 358/500\n",
            "1840/1840 [==============================] - 5s 2ms/step - loss: 0.1740 - val_loss: 0.1778\n",
            "Epoch 359/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1731 - val_loss: 0.1791\n",
            "Epoch 360/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1730 - val_loss: 0.1782\n",
            "Epoch 361/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1739 - val_loss: 0.1803\n",
            "Epoch 362/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1738 - val_loss: 0.1821\n",
            "Epoch 363/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1735 - val_loss: 0.1784\n",
            "Epoch 364/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1732 - val_loss: 0.1792\n",
            "Epoch 365/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1727 - val_loss: 0.1786\n",
            "Epoch 366/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1737 - val_loss: 0.1802\n",
            "Epoch 367/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1727 - val_loss: 0.1784\n",
            "Epoch 368/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1730 - val_loss: 0.1842\n",
            "Epoch 369/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1731 - val_loss: 0.1801\n",
            "Epoch 370/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1736 - val_loss: 0.1792\n",
            "Epoch 371/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1740 - val_loss: 0.1826\n",
            "Epoch 372/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1743 - val_loss: 0.1803\n",
            "Epoch 373/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1732 - val_loss: 0.1790\n",
            "Epoch 374/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1729 - val_loss: 0.1783\n",
            "Epoch 375/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1734 - val_loss: 0.1827\n",
            "Epoch 376/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1737 - val_loss: 0.1823\n",
            "Epoch 377/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1742 - val_loss: 0.1814\n",
            "Epoch 378/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1720 - val_loss: 0.1783\n",
            "Epoch 379/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1732 - val_loss: 0.1803\n",
            "Epoch 380/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1741 - val_loss: 0.1796\n",
            "Epoch 381/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1725 - val_loss: 0.1812\n",
            "Epoch 382/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1735 - val_loss: 0.1798\n",
            "Epoch 383/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1733 - val_loss: 0.1865\n",
            "Epoch 384/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1728 - val_loss: 0.1811\n",
            "Epoch 385/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1734 - val_loss: 0.1808\n",
            "Epoch 386/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1734 - val_loss: 0.1831\n",
            "Epoch 387/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1729 - val_loss: 0.1785\n",
            "Epoch 388/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1736 - val_loss: 0.1833\n",
            "Epoch 389/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1730 - val_loss: 0.1781\n",
            "Epoch 390/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1738 - val_loss: 0.1799\n",
            "Epoch 391/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1725 - val_loss: 0.1830\n",
            "Epoch 392/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1741 - val_loss: 0.1795\n",
            "Epoch 393/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1733 - val_loss: 0.1794\n",
            "Epoch 394/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1734 - val_loss: 0.1807\n",
            "Epoch 395/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1731 - val_loss: 0.1823\n",
            "Epoch 396/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1731 - val_loss: 0.1786\n",
            "Epoch 397/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1725 - val_loss: 0.1787\n",
            "Epoch 398/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1727 - val_loss: 0.1833\n",
            "Epoch 399/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1732 - val_loss: 0.1798\n",
            "Epoch 400/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1733 - val_loss: 0.1820\n",
            "Epoch 401/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1731 - val_loss: 0.1795\n",
            "Epoch 402/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1720 - val_loss: 0.1822\n",
            "Epoch 403/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1731 - val_loss: 0.1803\n",
            "Epoch 404/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1725 - val_loss: 0.1787\n",
            "Epoch 405/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1715 - val_loss: 0.1814\n",
            "Epoch 406/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1736 - val_loss: 0.1807\n",
            "Epoch 407/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1729 - val_loss: 0.1827\n",
            "Epoch 408/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1727 - val_loss: 0.1779\n",
            "Epoch 409/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1731 - val_loss: 0.1808\n",
            "Epoch 410/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1723 - val_loss: 0.1792\n",
            "Epoch 411/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1729 - val_loss: 0.1787\n",
            "Epoch 412/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1725 - val_loss: 0.1787\n",
            "Epoch 413/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1729 - val_loss: 0.1786\n",
            "Epoch 414/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1731 - val_loss: 0.1845\n",
            "Epoch 415/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1726 - val_loss: 0.1806\n",
            "Epoch 416/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1725 - val_loss: 0.1788\n",
            "Epoch 417/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1731 - val_loss: 0.1807\n",
            "Epoch 418/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1724 - val_loss: 0.1816\n",
            "Epoch 419/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1717 - val_loss: 0.1829\n",
            "Epoch 420/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1728 - val_loss: 0.1804\n",
            "Epoch 421/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1727 - val_loss: 0.1794\n",
            "Epoch 422/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1726 - val_loss: 0.1782\n",
            "Epoch 423/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1731 - val_loss: 0.1786\n",
            "Epoch 424/500\n",
            "1840/1840 [==============================] - 5s 2ms/step - loss: 0.1726 - val_loss: 0.1872\n",
            "Epoch 425/500\n",
            "1840/1840 [==============================] - 5s 2ms/step - loss: 0.1727 - val_loss: 0.1800\n",
            "Epoch 426/500\n",
            "1840/1840 [==============================] - 5s 2ms/step - loss: 0.1730 - val_loss: 0.1787\n",
            "Epoch 427/500\n",
            "1840/1840 [==============================] - 5s 2ms/step - loss: 0.1726 - val_loss: 0.1789\n",
            "Epoch 428/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1727 - val_loss: 0.1806\n",
            "Epoch 429/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1719 - val_loss: 0.1812\n",
            "Epoch 430/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1728 - val_loss: 0.1870\n",
            "Epoch 431/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1729 - val_loss: 0.1807\n",
            "Epoch 432/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1724 - val_loss: 0.1793\n",
            "Epoch 433/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1723 - val_loss: 0.1794\n",
            "Epoch 434/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1722 - val_loss: 0.1809\n",
            "Epoch 435/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1728 - val_loss: 0.1825\n",
            "Epoch 436/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1725 - val_loss: 0.1835\n",
            "Epoch 437/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1724 - val_loss: 0.1799\n",
            "Epoch 438/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1723 - val_loss: 0.1806\n",
            "Epoch 439/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1733 - val_loss: 0.1777\n",
            "Epoch 440/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1729 - val_loss: 0.1810\n",
            "Epoch 441/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1728 - val_loss: 0.1794\n",
            "Epoch 442/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1728 - val_loss: 0.1799\n",
            "Epoch 443/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1725 - val_loss: 0.1847\n",
            "Epoch 444/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1725 - val_loss: 0.1787\n",
            "Epoch 445/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1726 - val_loss: 0.1777\n",
            "Epoch 446/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1731 - val_loss: 0.1834\n",
            "Epoch 447/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1723 - val_loss: 0.1816\n",
            "Epoch 448/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1723 - val_loss: 0.1902\n",
            "Epoch 449/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1723 - val_loss: 0.1817\n",
            "Epoch 450/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1725 - val_loss: 0.1811\n",
            "Epoch 451/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1726 - val_loss: 0.1801\n",
            "Epoch 452/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1725 - val_loss: 0.1780\n",
            "Epoch 453/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1722 - val_loss: 0.1790\n",
            "Epoch 454/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1732 - val_loss: 0.1795\n",
            "Epoch 455/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1730 - val_loss: 0.1782\n",
            "Epoch 456/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1728 - val_loss: 0.1804\n",
            "Epoch 457/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1730 - val_loss: 0.1871\n",
            "Epoch 458/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1722 - val_loss: 0.1781\n",
            "Epoch 459/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1721 - val_loss: 0.1790\n",
            "Epoch 460/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1729 - val_loss: 0.1842\n",
            "Epoch 461/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1721 - val_loss: 0.1808\n",
            "Epoch 462/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1726 - val_loss: 0.1802\n",
            "Epoch 463/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1719 - val_loss: 0.1780\n",
            "Epoch 464/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1719 - val_loss: 0.1826\n",
            "Epoch 465/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1727 - val_loss: 0.1829\n",
            "Epoch 466/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1717 - val_loss: 0.1822\n",
            "Epoch 467/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1723 - val_loss: 0.1806\n",
            "Epoch 468/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1724 - val_loss: 0.1812\n",
            "Epoch 469/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1727 - val_loss: 0.1835\n",
            "Epoch 470/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1718 - val_loss: 0.1860\n",
            "Epoch 471/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1722 - val_loss: 0.1789\n",
            "Epoch 472/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1717 - val_loss: 0.1806\n",
            "Epoch 473/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1725 - val_loss: 0.1797\n",
            "Epoch 474/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1718 - val_loss: 0.1807\n",
            "Epoch 475/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1726 - val_loss: 0.1815\n",
            "Epoch 476/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1719 - val_loss: 0.1812\n",
            "Epoch 477/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1723 - val_loss: 0.1788\n",
            "Epoch 478/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1724 - val_loss: 0.1796\n",
            "Epoch 479/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1729 - val_loss: 0.1802\n",
            "Epoch 480/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1727 - val_loss: 0.1846\n",
            "Epoch 481/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1721 - val_loss: 0.1778\n",
            "Epoch 482/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1714 - val_loss: 0.1852\n",
            "Epoch 483/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1721 - val_loss: 0.1797\n",
            "Epoch 484/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1720 - val_loss: 0.1777\n",
            "Epoch 485/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1721 - val_loss: 0.1792\n",
            "Epoch 486/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1730 - val_loss: 0.1789\n",
            "Epoch 487/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1712 - val_loss: 0.1794\n",
            "Epoch 488/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1716 - val_loss: 0.1802\n",
            "Epoch 489/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1723 - val_loss: 0.1799\n",
            "Epoch 490/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1719 - val_loss: 0.1778\n",
            "Epoch 491/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1718 - val_loss: 0.1797\n",
            "Epoch 492/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1716 - val_loss: 0.1827\n",
            "Epoch 493/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1720 - val_loss: 0.1822\n",
            "Epoch 494/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1734 - val_loss: 0.1800\n",
            "Epoch 495/500\n",
            "1840/1840 [==============================] - 5s 3ms/step - loss: 0.1721 - val_loss: 0.1879\n",
            "Epoch 496/500\n",
            "1840/1840 [==============================] - 5s 2ms/step - loss: 0.1724 - val_loss: 0.1969\n",
            "Epoch 497/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1723 - val_loss: 0.1798\n",
            "Epoch 498/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1719 - val_loss: 0.1851\n",
            "Epoch 499/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1717 - val_loss: 0.1806\n",
            "Epoch 500/500\n",
            "1840/1840 [==============================] - 4s 2ms/step - loss: 0.1722 - val_loss: 0.1788\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6HSOKkVeRgh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "outputId": "eb069d55-067b-42fe-b47c-09e479fa070f"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 232,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_56\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_393 (Dense)            (None, 265)               70225     \n",
            "_________________________________________________________________\n",
            "dense_394 (Dense)            (None, 180)               47880     \n",
            "_________________________________________________________________\n",
            "dropout_100 (Dropout)        (None, 180)               0         \n",
            "_________________________________________________________________\n",
            "dense_395 (Dense)            (None, 150)               27150     \n",
            "_________________________________________________________________\n",
            "dropout_101 (Dropout)        (None, 150)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_168 (Bat (None, 150)               600       \n",
            "_________________________________________________________________\n",
            "dense_396 (Dense)            (None, 100)               15100     \n",
            "_________________________________________________________________\n",
            "dense_397 (Dense)            (None, 60)                6060      \n",
            "_________________________________________________________________\n",
            "batch_normalization_169 (Bat (None, 60)                240       \n",
            "_________________________________________________________________\n",
            "dense_398 (Dense)            (None, 20)                1220      \n",
            "_________________________________________________________________\n",
            "batch_normalization_170 (Bat (None, 20)                80        \n",
            "_________________________________________________________________\n",
            "dense_399 (Dense)            (None, 1)                 21        \n",
            "=================================================================\n",
            "Total params: 168,576\n",
            "Trainable params: 168,116\n",
            "Non-trainable params: 460\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkobPqsFK9oL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_pred_ANN = model.predict(X_train)"
      ],
      "execution_count": 239,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7sRnPOdeATN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_pred_ANN = Y_pred_ANN.reshape(1, -1)[0]"
      ],
      "execution_count": 240,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y99sWnuHhFR2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1392eeed-6077-4121-f60c-19ceb60dd8df"
      },
      "source": [
        "(1- (abs(np.expm1(Y_pred_ANN) - np.expm1(Y_train)) / np.expm1(Y_train)).mean()) * 100"
      ],
      "execution_count": 241,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "85.02374037393727"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 241
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YW5LFUlThPRr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}